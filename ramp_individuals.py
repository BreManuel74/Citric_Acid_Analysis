from pathlib import Path
from typing import Optional, Tuple
import math
import re

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import matplotlib.ticker as mticker
from matplotlib.patches import Patch
import matplotlib.transforms as mtransforms
 
# Global Matplotlib defaults (apply to all plots generated by this module)
# - Use Arial as the sans-serif font
# - Keep text as text in SVG outputs (not converted to paths)
plt.rcParams["font.family"] = "sans-serif"
plt.rcParams["font.sans-serif"] = ["Arial"]
plt.rcParams["svg.fonttype"] = "none"
"""Ramp analysis utilities: load master CSV, clean types, build per-ID series, and plot."""

plt.rcParams.update({
    "font.size": 11,          # base text
    "axes.titlesize": 13,     # ax.set_title / suptitle
    "axes.labelsize": 12,     # x/y labels
    "xtick.labelsize": 10,
    "ytick.labelsize": 10,
    "legend.fontsize": 10,
    "figure.titlesize": 14,   # plt.suptitle
})

# GUI file picker (standard library)
try:
	import tkinter as tk
	from tkinter import filedialog, messagebox
except Exception:
	tk = None
	filedialog = None
	messagebox = None

# Module-level cache so other analysis functions can reuse the master DF
_MASTER_DF: Optional[pd.DataFrame] = None
_MASTER_PATH: Optional[Path] = None


def _default_initialdir() -> Path:
	"""Best-effort initial directory for file dialogs: this script's folder."""
	try:
		return Path(__file__).resolve().parent
	except Exception:
		return Path.cwd()


def select_master_csv(initialdir: Optional[Path] = None) -> Optional[Path]:
	"""
	Open a GUI dialog to select the master CSV file.

	Returns the selected Path or None if the user cancels.
	"""
	if tk is None or filedialog is None:
		raise RuntimeError(
			"Tkinter is not available. Please ensure Python was installed with Tk support."
		)

	root = tk.Tk()
	root.withdraw()  # Hide the root window
	root.update_idletasks()

	start_dir = str((initialdir or _default_initialdir()))

	file_path = filedialog.askopenfilename(
		title="Select master CSV",
		initialdir=start_dir,
		filetypes=[
			("CSV files", "*.csv"),
			("All files", "*.*"),
		],
	)

	root.destroy()

	if not file_path:
		return None

	return Path(file_path)


def load_master_dataframe(csv_path: Path, *, encoding: Optional[str] = None) -> pd.DataFrame:
	"""
	Load the selected master CSV into a pandas DataFrame and cache it for reuse.

	Parameters:
		csv_path: Path to the CSV file
		encoding: Optional text encoding to use; if None, pandas will auto-detect

	Returns:
		pd.DataFrame loaded from the CSV
	"""
	global _MASTER_DF, _MASTER_PATH

	if not csv_path.exists() or not csv_path.is_file():
		raise FileNotFoundError(f"CSV path does not exist or is not a file: {csv_path}")

	df = pd.read_csv(csv_path, encoding=encoding)
	_MASTER_DF = df
	_MASTER_PATH = csv_path
	return df


def get_master_dataframe() -> Tuple[pd.DataFrame, Path]:
	"""
	Get the cached master DataFrame, prompting the user to select it if needed.

	Returns:
		(DataFrame, Path)
	"""
	global _MASTER_DF, _MASTER_PATH
	if _MASTER_DF is not None and _MASTER_PATH is not None:
		return _MASTER_DF, _MASTER_PATH

	chosen = select_master_csv()
	if chosen is None:
		raise KeyboardInterrupt("File selection canceled by user.")

	try:
		df = load_master_dataframe(chosen)
	except Exception as e:
		if messagebox is not None:
			messagebox.showerror("Load Error", f"Failed to load CSV:\n{e}")
		raise

	return df, chosen


def _preview_dataframe(df: pd.DataFrame, path: Path, *, n: int = 5) -> None:
	"""Print a concise preview of the loaded DataFrame to the console."""
	print(f"\nLoaded master CSV: {path}")
	print(f"Records: {len(df):,} | Columns: {len(df.columns):,}")
	with pd.option_context("display.max_columns", 100, "display.width", 160):
		print("\nHead:")
		print(df.head(n))


# ---- Cleaning and indexing helpers -----------------------------------------------------------

YES_NO_VALUES = {"yes": True, "no": False}


def clean_master_dataframe(df: pd.DataFrame) -> pd.DataFrame:
	"""
	Clean and standardize column types for downstream analysis.

	- Parse dates in 'DOB' and 'Date'
	- Coerce 'Daily Change' and 'Total Change' and 'Weight' to numeric
	- Strip percent signs in 'CA (%)' into float percentage (e.g., '3%' -> 3.0)
	- Convert any columns ending with '?' from yes/no to booleans
	- Drop rows with missing ID or Date
	- Sort by ID then Date
	"""
	df = df.copy()

	# Standardize column names we depend on (tolerate minor spacing/case issues)
	rename_map = {}
	for col in list(df.columns):
		canon = col.strip()
		if canon.lower() == "daily change":
			rename_map[col] = "Daily Change"
		elif canon.lower() == "total change":
			rename_map[col] = "Total Change"
		elif canon.lower() == "ca (%)":
			rename_map[col] = "CA (%)"
		elif canon.lower() == "date":
			rename_map[col] = "Date"
		elif canon.lower() == "dob":
			rename_map[col] = "DOB"
		elif canon.lower() == "weight":
			rename_map[col] = "Weight"
		elif canon.lower() == "id":
			rename_map[col] = "ID"
		elif canon.lower() == "sex":
			rename_map[col] = "Sex"
	if rename_map:
		df = df.rename(columns=rename_map)

	# Parse dates
	for dcol in ["DOB", "Date"]:
		if dcol in df.columns:
			df[dcol] = pd.to_datetime(df[dcol], errors="coerce")

	# Percent column
	if "CA (%)" in df.columns:
		df["CA (%)"] = (
			df["CA (%)"].astype(str).str.strip().str.replace("%", "", regex=False)
		)
		df["CA (%)"] = pd.to_numeric(df["CA (%)"], errors="coerce")

	# Numeric coercions
	for ncol in ["Daily Change", "Total Change", "Weight"]:
		if ncol in df.columns:
			df[ncol] = pd.to_numeric(df[ncol], errors="coerce")

	# yes/no -> bool for columns ending with '?'
	for col in df.columns:
		if col.endswith("?"):
			df[col] = (
				df[col]
				.astype(str)
				.str.strip()
				.str.lower()
				.map(YES_NO_VALUES)
				.astype("boolean")
			)

	# Remove rows without essential keys
	if "ID" in df.columns and "Date" in df.columns:
		df = df.dropna(subset=["ID", "Date"]).copy()

	# Sort for stable downstream grouping
	sort_cols = [c for c in ["ID", "Date"] if c in df.columns]
	if sort_cols:
		df = df.sort_values(sort_cols).reset_index(drop=True)

	return df


def _get_id_sex_map(df: pd.DataFrame) -> dict:
	"""
	Build a mapping from ID -> Sex ("M" or "F") using the first non-null value per ID.
	If Sex isn't available, returns an empty mapping.
	"""
	cdf = clean_master_dataframe(df)
	if "ID" not in cdf.columns or "Sex" not in cdf.columns:
		return {}

	def _norm_sex(x: pd.Series) -> Optional[str]:
		vals = x.dropna().astype(str).str.strip().str.upper()
		if vals.empty:
			return None
		v = vals.iloc[0]
		# Normalize common words
		if v.startswith("M"):
			return "M"
		if v.startswith("F"):
			return "F"
		return None

	sex_map = (
		cdf.groupby("ID")["Sex"].apply(_norm_sex).to_dict()
	)
	# Keys to str for consistency with series_by_id
	return {str(k): v for k, v in sex_map.items()}


def _sex_to_style(sex: Optional[str]) -> tuple[str, str]:
	"""Return (color, marker) based on sex: M=green/square, F=purple/circle, unknown=gray/triangle."""
	if sex == "M":
		return ("green", "s")
	if sex == "F":
		return ("purple", "o")
	return ("gray", "^")


def _add_day_number_column(df: pd.DataFrame) -> pd.DataFrame:
    """
    Add a per-ID 'Day' column where the first date for each ID is day 1,
    and subsequent rows are 1 + calendar days since the first date.
    Requires 'ID' and 'Date' columns with Date as datetime.
    """
    if not {"ID", "Date"}.issubset(df.columns):
        return df
    df = df.copy()
    # Ensure sorted for clarity (clean_master_dataframe already does this)
    df = df.sort_values(["ID", "Date"]).reset_index(drop=True)
    # Compute day number per ID
    first_dates = df.groupby("ID")["Date"].transform("min")
    df["Day"] = (df["Date"] - first_dates).dt.days + 1
    return df


# ---- CA% by day and background shading ------------------------------------------------------

CA_BG_COLORS = {
	0: "#FFFFFF",   # (0%)
	1: "#000000",   # (1%)
	2: "#FFFFFF",   # (2%)
	3: "#000000",   # (3%)
	4: "#FFFFFF",   # (4%)
}


def build_ca_percent_series_by_day(df: pd.DataFrame) -> pd.Series:
	"""
	Build a Series indexed by per-mouse Day (integer) giving the CA (%) value.
	Since CA (%) is the same schedule across IDs, we take the per-day mode across IDs.
	Requires 'CA (%)' present and dates parsed.
	"""
	cdf = clean_master_dataframe(df)
	if "CA (%)" not in cdf.columns:
		raise ValueError("'CA (%)' column not found in DataFrame")
	cdf = _add_day_number_column(cdf)
	if "Day" not in cdf.columns:
		raise ValueError("Failed to compute 'Day' column for CA% series")

	# Keep rows with Day and CA
	tmp = cdf.dropna(subset=["Day", "CA (%)"]).copy()
	if tmp.empty:
		return pd.Series(dtype=float)

	def _mode_or_mean(s: pd.Series) -> float:
		m = s.mode(dropna=True)
		if not m.empty:
			return float(m.iloc[0])
		return float(s.mean())

	ca_by_day = (
		tmp.groupby("Day")["CA (%)"].apply(_mode_or_mean).sort_index()
	)
	return ca_by_day


def _add_ca_background(ax: plt.Axes, ca_by_day: pd.Series, *, alpha: float = 0.15) -> None:
	"""
	Deprecated: Background shading is no longer used.
	This function is retained for backward compatibility but does nothing.
	"""
	return


def _add_ca_background_legend(ax: plt.Axes, *, loc: str = "upper left") -> None:
	"""Add a legend explaining CA% background colors as colored patches."""
	patches = [
		Patch(facecolor=CA_BG_COLORS.get(level, "#F0F0F0"), edgecolor="black", label=f"{level}%")
		for level in sorted(CA_BG_COLORS.keys())
	]
	legend_bg = ax.legend(handles=patches, title="CA (%)", loc=loc, frameon=True)
	ax.add_artist(legend_bg)


def _add_ca_block_boundaries(
	ax: plt.Axes,
	ca_by_day: pd.Series,
	*,
	linestyle: str = "--",
	color: str = "0.2",
	linewidth: float = 1.2,
	alpha: float = 0.9,
) -> None:
	"""
	Draw vertical dashed lines at the last day index of each contiguous CA% block,
	EXCEPT for the very last block (no line at the end of the final percentage segment).
	Expects the x-axis to use integer day numbers (1, 2, ...).
	"""
	if ca_by_day is None or ca_by_day.empty:
		return
	series = ca_by_day.dropna().astype(int)
	if series.empty:
		return
	# Identify contiguous segments where CA% is constant and collect their end days
	seg_ids = (series != series.shift(1)).cumsum()
	end_days: list[int] = []
	for _, seg in series.groupby(seg_ids):
		end_days.append(int(seg.index.max()))
	# Skip the last segment's end by dropping the final end_day
	if end_days:
		for end_day in end_days[:-1]:
			ax.axvline(end_day, linestyle=linestyle, color=color, linewidth=linewidth, alpha=alpha, zorder=0)


def _add_ca_block_labels(ax: plt.Axes, ca_by_day: pd.Series) -> None:
	"""
	Add floating text labels (e.g., '1%') centered over each contiguous CA% block.
	X uses data coordinates (day center); Y uses axes fraction near top for consistent placement.
	"""
	if ca_by_day is None or ca_by_day.empty:
		return
	series = ca_by_day.dropna().astype(int)
	if series.empty:
		return

	seg_ids = (series != series.shift(1)).cumsum()
	trans = mtransforms.blended_transform_factory(ax.transData, ax.transAxes)
	for _, seg in series.groupby(seg_ids):
		ca_val = int(seg.iloc[0])
		start = int(seg.index.min())
		end = int(seg.index.max())
		x_center = (start + end) / 2.0
		ax.text(
			x_center,
			0.98,
			f"{ca_val}%",
			transform=trans,
			ha="center",
			va="top",
			color="black",
			fontsize=10,
			fontweight="bold",
			zorder=10,
		)


def build_daily_change_series_by_id(df: pd.DataFrame, *, index: str = "date") -> dict:
	"""
	For each ID, return a pandas Series of 'Daily Change' indexed by either Date or Day.

	Assumptions and behavior:
	- Drops rows where Daily Change is NaN.
	- If duplicate index values exist per ID (same Date or same Day), keep the last one.
	- For index='date': index is a DateTimeIndex sorted ascending.
	- For index='day': index is integer day numbers starting from 1 per ID.

	Returns:
		dict[str, pd.Series]
	"""
	required = {"ID", "Date", "Daily Change"}
	missing = required - set(df.columns)
	if missing:
		raise ValueError(f"DataFrame missing required columns: {sorted(missing)}")

	# Clean first to ensure types/indexing are reliable
	cdf = clean_master_dataframe(df)
	if index == "day":
		cdf = _add_day_number_column(cdf)
		if "Day" not in cdf.columns:
			raise ValueError("Failed to compute 'Day' column. Ensure 'Date' parsing succeeded.")

	series_by_id: dict[str, pd.Series] = {}
	for gid, g in cdf.groupby("ID", dropna=True):
		# Drop NaN daily change rows
		g = g.dropna(subset=["Daily Change"])  # type: ignore[assignment]

		# Set index based on requested mode and ensure uniqueness by keeping last
		if index == "day":
			idx_col = "Day"
			# Make sure day is integer
			g[idx_col] = g[idx_col].astype("Int64")
			ser = g.set_index(idx_col)["Daily Change"].sort_index()
			# Aggregate duplicates by index
			s = ser.groupby(level=0).last()
		else:
			ser = g.set_index("Date")["Daily Change"].sort_index()
			s = ser.groupby(level=0).last()
		# Name the series for clarity
		s.name = str(gid)
		series_by_id[str(gid)] = s

	return series_by_id


def main() -> None:
	"""Interactive entrypoint: select and load the master CSV, then preview it."""
	try:
		df, path = get_master_dataframe()
	except KeyboardInterrupt:
		# User canceled selectionâ€”exit quietly
		print("Selection canceled. No file loaded.")
		return
	_preview_dataframe(df, path)

	# Demonstrate building the per-ID daily change series
	try:
		series_by_id = build_daily_change_series_by_id(df, index="day")
		print("\nPer-ID Daily Change series built:")
		# Show a brief sample for up to 2 IDs
		for i, (mid, s) in enumerate(series_by_id.items()):
			print(f"\nID: {mid} | points: {len(s)}")
			print(s.head(3))
			if i >= 1:
				break
	except Exception as e:
		print(f"\nWarning: failed to build per-ID series: {e}")

	# Plot daily changes over time for each mouse in one figure
	try:
		plot_daily_change_by_id(df, use_day_number=True, save_svg=True)
	except Exception as e:
		print(f"\nWarning: failed to plot daily changes: {e}")


def plot_daily_change_by_id(
	df: pd.DataFrame,
	*,
	ids: Optional[list[str]] = None,
	title: Optional[str] = None,
	save_path: Optional[Path] = None,
	show: bool = True,
	use_day_number: bool = True,
	# Quick-save to SVG in current working directory
	save_svg: bool = False,
	svg_filename: Optional[str] = None,
	# Tick interval controls (applies when using day numbers)
	x_tick_interval: Optional[int] = None,
	y_tick_interval: Optional[int] = None,
	# Target number of ticks for auto step sizing (higher -> smaller steps)
	x_target_ticks: int = 10,
	y_target_ticks: int = 7,
) -> plt.Figure:
	"""
	Create a single plot showing Daily Change over Date for each mouse (ID).

	Parameters:
		df: Master DataFrame
		ids: Optional subset of IDs to plot; by default plots all IDs found
		title: Optional plot title
		save_path: If provided, saves the figure to this path
		show: If True, calls plt.show() at the end

	Returns:
		The matplotlib Figure object
	"""
	series_by_id = build_daily_change_series_by_id(df, index=("day" if use_day_number else "date"))
	sex_map = _get_id_sex_map(df)

	# If using day numbers, compute CA% per day (draw background later after axis is set)
	if use_day_number:
		try:
			ca_by_day = build_ca_percent_series_by_day(df)
		except Exception:
			ca_by_day = pd.Series(dtype=float)

	# Filter to requested IDs if provided
	if ids is not None:
		series_by_id = {k: v for k, v in series_by_id.items() if k in set(ids)}

	if not series_by_id:
		raise ValueError("No series available to plot. Check input DataFrame and 'ids' filter.")

	fig, ax = plt.subplots(figsize=(11, 6))

	# Draw background after plotting and before legend, once axes are scaled

	# Plot each ID as a separate line
	for mid, s in series_by_id.items():
		if s.empty:
			continue
		color, marker = _sex_to_style(sex_map.get(mid))
		ax.plot(
			s.index,
			s.values,
			label=str(mid),
			marker=marker,
			markersize=3,
			linewidth=1.5,
			alpha=0.9,
			color=color,
		)

	ax.set_xlabel("Day" if use_day_number else "Date")
	ax.set_ylabel("Daily Change")
	# Remove all grid lines; we'll draw only a single dotted reference line at y=0
	ax.grid(False)

	# Axis formatting: integers for day numbers, concise dates for datetimes
	if use_day_number:
		ax.xaxis.set_major_locator(mticker.MaxNLocator(integer=True))
	else:
		locator = mdates.AutoDateLocator()
		formatter = mdates.ConciseDateFormatter(locator)
		ax.xaxis.set_major_locator(locator)
		ax.xaxis.set_major_formatter(formatter)
		for label in ax.get_xticklabels():
			label.set_rotation(0)

	if title is None:
		title = "Daily Change by Day Number per Mouse" if use_day_number else "Daily Change over Time by Mouse"
	ax.set_title(title)

	# Apply common styling: remove top/right spines, inward ticks, no x margins, start x at 0 for day plots
	apply_common_plot_style(
        ax,
        start_x_at_zero=False,
        remove_top_right=True,
        remove_x_margins=True,
        remove_y_margins=True,
        ticks_in=True,
    )

	# Fixed-interval ticks based on data size, extending one extra step beyond data range
	# Gather global data bounds
	all_y = np.concatenate([s.values for s in series_by_id.values() if len(s) > 0])
	y_data_min = float(np.nanmin(all_y)) if all_y.size else 0.0
	y_data_max = float(np.nanmax(all_y)) if all_y.size else 1.0

	if use_day_number:
		all_x = np.concatenate([np.asarray(s.index, dtype=float) for s in series_by_id.values() if len(s) > 0])
		x_data_min = int(np.nanmin(all_x)) if all_x.size else 0
		x_data_max = int(np.nanmax(all_x)) if all_x.size else 1
		# Choose or compute x step and apply with clamp at zero
		x_step = x_tick_interval or _auto_integer_step(
			x_data_min, x_data_max, target_ticks=x_target_ticks, allow_sub5=True
		)
		_apply_integer_axis(
			ax,
			axis='x',
			data_min=x_data_min,
			data_max=x_data_max,
			step=x_step,
			clamp_min=0,
			left_pad_steps=1,
			right_pad_steps=1,
		)
	else:
		# Leave date axis as previously configured
		pass

	# Y axis: integer ticks without decimals
	y_step = y_tick_interval or _auto_integer_step(y_data_min, y_data_max, target_ticks=y_target_ticks)
	_apply_integer_axis(
		ax,
		axis='y',
		data_min=y_data_min,
		data_max=y_data_max,
		step=y_step,
		left_pad_steps=0,
		right_pad_steps=1,
	)

	# Now that axes are finalized, draw CA background and labels (clips at day 1 correctly)
	if use_day_number:
		# Draw dashed boundaries at the end of each CA% block (no shading)
		_add_ca_block_boundaries(ax, ca_by_day)
		_add_ca_block_labels(ax, ca_by_day)

	# Place legend outside if many IDs, else in best location
	if len(series_by_id) > 6:
		ax.legend(title="ID", bbox_to_anchor=(1.02, 1), loc="upper left", borderaxespad=0.)
		fig.tight_layout(rect=[0, 0, 0.85, 1])
	else:
		ax.legend(title="ID", loc="best")
		fig.tight_layout()

	if save_path is not None:
		fig.savefig(str(save_path), dpi=200, bbox_inches="tight")

	# Optionally save an SVG in the current working directory, using a title-derived filename
	if save_svg:
		base = svg_filename or (title or "daily_change_by_id")
		safe = re.sub(r"[^A-Za-z0-9._-]+", "-", str(base)).strip("-_.") or "plot"
		if not safe.lower().endswith(".svg"):
			safe += ".svg"
		out_path = Path.cwd() / safe
		fig.savefig(str(out_path), format="svg", bbox_inches="tight")
		print(f"Saved SVG to: {out_path}")

	if show:
		plt.show()

	return fig


def apply_common_plot_style(
	ax: plt.Axes,
	*,
	start_x_at_zero: bool = False,
	remove_top_right: bool = True,
	remove_x_margins: bool = True,
	remove_y_margins: bool = True,
	ticks_in: bool = True,
	draw_zero_dotted_line: bool = True,
) -> plt.Axes:
	"""
	Apply a reusable set of plot styles:
	- Optionally start x-axis at 0
	- Remove x-axis margins/whitespace
	- Remove top and right spines
	- Set all ticks to face inward

	Return the styled Axes for chaining.
	"""
	if remove_top_right:
		for side in ("top", "right"):
			ax.spines[side].set_visible(False)
	if ticks_in:
		ax.tick_params(direction="in", which="both", length=5)
	if remove_x_margins:
		ax.margins(x=0)
	if remove_y_margins:
		# Remove extra headroom/footroom on Y and align to data bounds
		ax.margins(y=0)
		ax.autoscale(axis="y", tight=True)
	if start_x_at_zero:
		# Preserve current right limit if set; only enforce left=0
		left, right = ax.get_xlim()
		ax.set_xlim(left=0, right=right)

	# Draw only a single dotted line at y=0 as a reference (no other dotted grid lines)
	if draw_zero_dotted_line:
		try:
			_add_zero_reference_line(ax, axis='y', linestyle='-', color='0', linewidth=1.5, alpha=0.8)
		except Exception:
			# If limits or scales are unusual, ignore drawing the reference line
			pass

	# Do not touch ticks here; ticks will be set by plotting function based on data
	return ax


def _add_zero_reference_line(
	ax: plt.Axes,
	*,
	axis: str = 'y',
	linestyle: str = ':',
	color: str = '0.3',
	linewidth: float = 1.0,
	alpha: float = 0.8,
) -> None:
	"""
	Draw a single reference line at 0 on the specified axis.
	axis='y' -> horizontal line at y=0; axis='x' -> vertical line at x=0.
	"""
	if axis == 'y':
		ax.axhline(0, linestyle=linestyle, color=color, linewidth=linewidth, alpha=alpha, zorder=1)
	elif axis == 'x':
		ax.axvline(0, linestyle=linestyle, color=color, linewidth=linewidth, alpha=alpha, zorder=1)


def _auto_integer_step(
	vmin: float,
	vmax: float,
	target_ticks: int = 7,
	allow_sub5: bool = False,
) -> int:
	"""Choose a 'nice' integer step so about target_ticks cover the range.

	Always returns at least 1. Uses a 1-2-(2.5)-3-4-5 progression when allow_sub5=True,
	otherwise the classic 1-2-5 progression, all scaled by powers of 10.
	"""
	if not (np.isfinite(vmin) and np.isfinite(vmax)):
		return 1
	range_int = int(abs(math.ceil(vmax) - math.floor(vmin)))
	if range_int <= 0:
		return 1
	# Desired step near range/target_ticks
	approx = max(1.0, range_int / max(1, target_ticks))
	pow10 = 10 ** int(math.floor(math.log10(approx)))
	multipliers = (1, 2, 2.5, 3, 4, 5) if allow_sub5 else (1, 2, 5)
	for m in multipliers:
		# ceil to preserve 2.5->3, etc., then clamp to >=1
		step = int(max(1, math.ceil(m * pow10)))
		if range_int / step <= target_ticks:
			return step
	# Fallback: next power of ten
	return int(max(1, 10 * pow10))


def _apply_integer_axis(
	ax: plt.Axes,
	*,
	axis: str,
	data_min: float,
	data_max: float,
	step: int,
	clamp_min: Optional[int] = None,
    left_pad_steps: int = 0,
    right_pad_steps: int = 1,
) -> None:
	"""Apply integer ticks and limits to the chosen axis with one extra step beyond data.

	- Extends min down by left_pad_steps and max up by right_pad_steps relative to step-aligned bounds.
	- Optionally clamps the lower bound at a specified minimum (e.g., 1 for day-number X axis).
	- Formats tick labels as integers (no decimals).
	"""
	step = int(max(1, step))
	# Align to the step grid first
	base_start = int(math.floor(data_min / step) * step)
	base_end_lower = int(math.floor(data_max / step) * step)
	tick_start = base_start - left_pad_steps * step
	end = base_end_lower + right_pad_steps * step
	# Determine visible axis start with optional clamp
	start = tick_start
	if clamp_min is not None and start < clamp_min:
		start = clamp_min
	if end <= start:
		end = start + step
	# Build ticks anchored to the base grid, then filter to visible range
	all_ticks = list(range(tick_start, end + 1, step))
	ticks = [t for t in all_ticks if start <= t <= end]
	if axis == 'x':
		ax.set_xlim(start, end)
		ax.set_xticks(ticks)
		ax.xaxis.set_major_formatter(mticker.FormatStrFormatter('%d'))
	elif axis == 'y':
		ax.set_ylim(start, end)
		ax.set_yticks(ticks)
		ax.yaxis.set_major_formatter(mticker.FormatStrFormatter('%.0f'))


def _ensure_endpoint_ticks(ax: plt.Axes, *, x_integer: bool = False, tol: float = 1e-9) -> None:
	"""
	Show ONLY the lowest and highest tick labels on both axes.
	For x_integer=True (day-number plots), endpoints are rounded to integers
	and formatted without decimals. Y-axis labels are formatted without decimals.
	"""
	# X-axis endpoints
	xmin, xmax = ax.get_xlim()
	current_xticks = list(ax.get_xticks())
	if x_integer:
		# Round x-limits to integers for day-number plots
		xmin_i = int(np.floor(xmin + tol))
		xmax_i = int(np.ceil(xmax - tol))
		if xmin_i == xmax_i:
			# Expand a degenerate range minimally
			xmax_i = xmin_i + 1
		ax.set_xlim(xmin_i, xmax_i)
		# Only set endpoints if there are no internal ticks (<=2); otherwise leave interval ticks as-is
		if len(current_xticks) <= 2:
			ax.set_xticks([xmin_i, xmax_i])
		# Always format as integers
		ax.xaxis.set_major_formatter(mticker.FormatStrFormatter('%d'))
	else:
		# Date mode: only set endpoints if there are no internal ticks; otherwise leave ticks as-is
		if len(current_xticks) <= 2:
			ax.set_xticks([xmin, xmax])

	# Y-axis endpoints, formatted without decimals
	ymin, ymax = ax.get_ylim()
	if ymin == ymax:
		# Expand minimally to avoid degenerate axis
		ymax = ymin + 1.0
		ax.set_ylim(ymin, ymax)
	current_yticks = list(ax.get_yticks())
	# Only set endpoints if there are no internal ticks
	if len(current_yticks) <= 2:
		ax.set_yticks([ymin, ymax])
	ax.yaxis.set_major_formatter(mticker.FormatStrFormatter('%.0f'))


if __name__ == "__main__":
	main()
